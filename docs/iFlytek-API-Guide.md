# 科大讯飞语音识别 API 集成指南

## 概述

本项目使用科大讯飞的**语音听写（流式版）WebSocket API**进行实时语音识别。

API 文档：https://www.xfyun.cn/doc/asr/voicedictation/API.html

## API 特点

- **实时流式识别**：支持边说边识别，适合语音输入场景
- **高准确率**：针对中文普通话优化
- **领域定制**：支持旅游领域（trip）参数优化
- **动态修正**：开启wpgs参数，实时修正识别结果
- **标点符号**：自动添加标点符号

## 配置步骤

### 1. 获取API凭证

1. 访问 [科大讯飞开放平台](https://www.xfyun.cn/)
2. 注册并登录账号
3. 进入控制台 → 创建应用
4. 添加服务：选择"语音听写（流式版）"
5. 获取以下凭证：
   - APPID
   - APIKey
   - APISecret

### 2. 设置环境变量

在项目的 `frontend/.env.local` 文件中添加：

```bash
VITE_VOICE_APP_ID=your_app_id_here
VITE_VOICE_API_KEY=your_api_key_here
VITE_VOICE_API_SECRET=your_api_secret_here
```

**注意**：`.env.local` 文件不应提交到版本控制系统。

### 3. IP白名单设置（可选）

在控制台中可以配置IP白名单。开发环境建议关闭IP白名单限制。

## 技术实现

### WebSocket 连接流程

1. **生成鉴权URL**
   - 使用 HMAC-SHA256 算法生成签名
   - 签名参数包括：host、date、request-line
   - 将签名信息base64编码后作为URL参数

2. **建立WebSocket连接**
   - 连接地址：`wss://iat-api.xfyun.cn/v2/iat`
   - 携带鉴权参数

3. **发送音频数据**
   - 第一帧：包含业务参数（language、domain、accent等）
   - 中间帧：分块发送音频数据（每帧1280字节，间隔40ms）
   - 最后一帧：标识音频结束（status=2）

4. **接收识别结果**
   - 实时返回识别文本
   - 解析JSON响应获取识别结果
   - 最后一帧返回完整识别文本

### 音频格式要求

- **采样率**：16kHz（推荐）或 8kHz
- **采样精度**：16bit
- **声道**：单声道
- **格式**：PCM（原始音频）
- **最长时长**：60秒

### 业务参数说明

```javascript
{
  language: 'zh_cn',      // 中文
  domain: 'iat',          // 日常用语
  accent: 'mandarin',     // 普通话
  vad_eos: 3000,         // 后端点检测静默时间（3秒）
  dwa: 'wpgs',           // 开启动态修正
  pd: 'trip',            // 旅游领域
  ptt: 1                 // 开启标点符号
}
```

### 动态修正说明

开启动态修正（`dwa: 'wpgs'`）后，识别结果会包含以下字段：

- **`sn`**: 结果序号（从1开始）
  - 用于标识每次返回的结果位置
  - 必须使用 `sn` 作为索引，而不是数组下标

- **`pgs`**: 结果处理方式
  - `"apd"`: 追加模式，将当前结果追加到之前的结果后面
  - `"rpl"`: 替换模式，需要替换之前的部分结果
  
- **`rg`**: 替换范围（仅在 `pgs: "rpl"` 时存在）
  - 格式：`[startSn, endSn]`
  - 表示要替换序号为 `startSn` 到 `endSn` 的结果
  - **注意**: `rg` 中的值是 `sn` 序号，不是数组索引

**示例**：
```javascript
// 第1次返回: sn=1, pgs: "apd"
{ result: "我想" }  // Map: {1: "我想"}

// 第2次返回: sn=2, pgs: "apd" 
{ result: "一个人" }  // Map: {1: "我想", 2: "一个人"}

// 第3次返回: sn=3, pgs: "rpl", rg: [2, 2]
{ result: "一个人去" }  // Map: {1: "我想", 3: "一个人去"}  (删除了sn=2，添加sn=3)

// 第4次返回: sn=4, pgs: "apd"
{ result: "北京玩" }  // Map: {1: "我想", 3: "一个人去", 4: "北京玩"}

// 最终结果: "我想一个人去北京玩"
```

**重要**: 
1. ❌ **错误**: 使用数组索引处理 `rg` 范围，会导致第一个字重复
2. ✅ **正确**: 使用 Map 存储，以 `sn` 为 key，正确删除和添加结果

## 错误处理

### 常见错误码

| 错误码 | 说明 | 解决方案 |
|-------|------|---------|
| 10005 | appid授权失败 | 检查APPID是否正确，是否开通了听写服务 |
| 10114 | 会话超时 | 检查整个会话是否超过60秒 |
| 10163 | 缺少必传参数 | 检查参数是否正确上传 |
| 10200 | 读取数据超时 | 检查是否累计10秒未发送数据 |
| 11200 | 没有权限 | 检查是否使用了未授权的功能 |
| 11201 | 日流控超限 | 联系商务提高每日调用次数 |

### 错误处理策略

1. **API未配置**：抛出明确错误，提示用户配置环境变量
2. **网络错误**：提示用户检查网络连接
3. **识别失败**：显示具体错误信息，不使用默认数据
4. **超时处理**：设置60秒超时，自动关闭连接

## 使用示例

```typescript
import { voiceService } from '@/services/voice/iflytek';

// 识别音频
try {
  const result = await voiceService.transcribeAudio(audioBlob);
  console.log('识别结果:', result.text);
  console.log('置信度:', result.confidence);
} catch (error) {
  console.error('识别失败:', error.message);
  // 显示错误提示给用户
}
```

## 性能优化建议

1. **音频分帧**：每次发送1280字节，间隔40ms
2. **超时控制**：设置合理的超时时间（60秒）
3. **连接复用**：单次识别完成后关闭连接
4. **错误重试**：网络错误时可实现重试机制

## 测试建议

### 开发测试

- 使用示例音频文件测试基本功能
- 测试不同音频质量和时长
- 验证错误处理逻辑

### 语音质量建议

- 在安静环境中录音
- 清晰地发音
- 避免背景噪音
- 控制录音时长在10-30秒

## 配额限制

- **免费版**：每日有调用次数限制
- **并发限制**：默认50路并发
- **音频时长**：单次最长60秒

如需更多配额，请联系科大讯飞商务。

## 更新日志

### 2025-10-24 v1.2
- **修复**: 第一个字重复的问题
- 使用 Map<sn, text> 代替数组存储结果
- `rg` 范围使用 `sn` 序号而非数组索引
- 改进调试日志，显示 sn、pgs、rg 信息

### 2025-10-24 v1.1
- **修复**: 动态修正导致的识别结果重复问题
- 正确处理 `pgs` (apd/rpl) 和 `rg` 字段
- 使用结果缓存数组进行动态修正
- 添加调试日志输出

### 2025-10-24 v1.0
- 从转写API切换到WebSocket流式API
- 实现实时语音识别
- 添加完整的错误处理
- 移除默认模拟数据，改为抛出明确错误
- 优化音频格式转换（WebM → PCM）
- 添加旅游领域参数优化

## 参考链接

- [API文档](https://www.xfyun.cn/doc/asr/voicedictation/API.html)
- [控制台](https://console.xfyun.cn/)
- [音频格式说明](https://www.xfyun.cn/doc/asr/voicedictation/Audio.html)
- [错误码查询](https://www.xfyun.cn/document/error-code)
